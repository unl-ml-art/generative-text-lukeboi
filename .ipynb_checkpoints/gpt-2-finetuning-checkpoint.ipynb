{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning the GPT-2 Model \n",
    "\n",
    "This notebook explores the GPT-2 model released by OpenAI on February 14th, 2019. This blog post 'Better Language Models and Their Implications' https://openai.com/blog/better-language-models/, discusses the project.\n",
    "\n",
    "Due to concerns over the effectiveness of their model (this reasoning bears questioning), they have only released a smaller version (117M parameters vs 1.5B parameters) of their larger model. See their reasoning [here](https://openai.com/blog/better-language-models/#releasestrategy). They also did not release any of the training software they used to produce the full GPT-2 model.\n",
    "\n",
    "Data: The GPT-2 model was trained on a corpus of 8 million webpages (40GB of text) scraped from outgoing reddit links with Karma > 3. This if a form of human/collaborative filtering, and supposed indicator of \"quality\" of the outgoing links. See their data curation approach [here](https://openai.com/blog/better-language-models/#fn1).  \n",
    "\n",
    "Paper: [Language Models are Unsupervised Task Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "\n",
    "Code: https://github.com/openai/gpt-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning vs. Retraining\n",
    "\n",
    "Training a 1.5B parameter model requires an enormous corpus of text (8M webpages yielding 40GB of plain text). Even with a reduced 117M parameter GPT-2, training this architecture on a small dataset (where data is smaller than the number of parameters) reduces the networks ability to generalize and likely results in overfitting. Fine-tuning a network means taking that high-parameter, pretrained network, and continuing training (via backpropagation) with our new, smaller dataset. The caveat here is that the new dataset needs to resemble/be similar in kind to the original training data.\n",
    "\n",
    "Even if we wanted to train GPT-2 architecture from scratch, OpenAI has not provided access to the training data or training code.\n",
    "\n",
    "The example below wraps up the gpt-2 fine-tuning process in a very simple interface, installed via pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt-2-simple in /home/emar349/lukethecdr/.local/lib/python3.9/site-packages (0.8.1)\n",
      "Requirement already satisfied: tqdm in /home/emar349/lukethecdr/.local/lib/python3.9/site-packages (from gpt-2-simple) (4.62.3)\n",
      "Requirement already satisfied: numpy in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from gpt-2-simple) (1.19.5)\n",
      "Requirement already satisfied: tensorflow>=2.5.1 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from gpt-2-simple) (2.6.0)\n",
      "Requirement already satisfied: regex in /home/emar349/lukethecdr/.local/lib/python3.9/site-packages (from gpt-2-simple) (2022.1.18)\n",
      "Requirement already satisfied: requests in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from gpt-2-simple) (2.25.1)\n",
      "Requirement already satisfied: toposort in /home/emar349/lukethecdr/.local/lib/python3.9/site-packages (from gpt-2-simple) (1.7)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.39 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.39.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.7.4.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.6.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.37.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.12)\n",
      "Requirement already satisfied: keras~=2.6 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.6.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from requests->gpt-2-simple) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from requests->gpt-2-simple) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from requests->gpt-2-simple) (1.26.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from requests->gpt-2-simple) (2.10)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (2.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.6.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (59.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gpt-2-simple --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "model_name = \"124M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 703Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 4.22Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 894Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:08, 60.3Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 773Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 5.43Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 5.42Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 03:05:55.152806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-22 03:05:55.833141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n",
      "2022-02-22 03:05:58.675380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-600\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-600\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 0 tokens\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_309215/1119256444.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_tf_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m gpt2.finetune(sess,\n\u001b[0m\u001b[1;32m      3\u001b[0m               \u001b[0;34m'dataset.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               steps=300)#1000)   # steps is max number of training steps\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msample_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mgenerate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maccumulate_gradients\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mgenerate_samples\u001b[0;34m()\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mcontext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpt_2_simple/src/load_dataset.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         assert length < self.total_size // len(\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset files are too small to sample {} tokens at a time\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess,\n",
    "              'dataset.txt',\n",
    "              model_name=model_name,\n",
    "              steps=300)#1000)   # steps is max number of training steps\n",
    "\n",
    "gpt2.generate(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities\n",
    "\n",
    "- Explore different finetuning texts (of your choice) and their results.\n",
    "  - Observe how the size of the text (num characters) relate to the number of parameters of the GPT-2 model you are working with.\n",
    "  - Observe the loss \n",
    "  - Look for over-fitting (loss at or near 0)\n",
    "- Try the other sizes of published models, how do they change the complexity/intelligibility of generated text. gpt_2_simple wraps the \"small\" 124M and \"medium\" 355M models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- Example is from [https://github.com/minimaxir/gpt-2-simple](https://github.com/minimaxir/gpt-2-simple). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow GPU 2.6 (py39)",
   "language": "python",
   "name": "tensorflow-gpu-2.6-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
